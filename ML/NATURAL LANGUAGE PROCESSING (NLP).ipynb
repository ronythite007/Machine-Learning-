{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6391b63e-db4c-4f5a-82e2-80290c191d85",
   "metadata": {},
   "source": [
    "# Developing an NLP application to analyze and process text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeddbfe3-4bad-4231-a9ee-ade1ff220998",
   "metadata": {},
   "source": [
    "## Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80bdc13-e351-4693-b505-cdc3d73d814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e0051-9b53-4688-b73d-c901b04355a1",
   "metadata": {},
   "source": [
    "## Download necessary NLTK data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd018787-eb2d-49a3-bdd5-f936ca1acb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rohan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rohan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rohan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a1727-2d57-4ba0-8a0a-a9123b869428",
   "metadata": {},
   "source": [
    "## Function to preprocess text\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62bafe84-58ba-4672-86e4-5b838ed036c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenization: Text ko words mein split karna\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Stop-word Removal: Common words ko hatana\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Stemming: Words ko base form mein convert karna\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    \n",
    "    # Lemmatization: Words ko dictionary form mein convert karna\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in stemmed_tokens]\n",
    "    \n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82338cf-dc61-4053-8e10-f9ad92c7a1db",
   "metadata": {},
   "source": [
    "## Function to preprocess text and get word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a539e3-6d8f-4b6d-b722-14a53565ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_embed(text, model):\n",
    "    # Text ko preprocess karna\n",
    "    tokens = preprocess_text(text)\n",
    "    \n",
    "    # Embeddings ko get karna\n",
    "    embeddings = [model[word] for word in tokens if word in model]\n",
    "    \n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e990a9a-8d11-4d6a-bff7-e3ff8762a11d",
   "metadata": {},
   "source": [
    "## Pre-trained Word2Vec model ko load karte hain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "321927fa-0a36-4ff3-a880-7e18ef5f8283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051657b-c293-4e67-974e-a763b61761a2",
   "metadata": {},
   "source": [
    "### Input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1df09b38-51f1-4f9a-ae7f-b87902d3c5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text :  Hi i am rohan thite from pune \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Text: ['hi', 'rohan', 'thite', 'pune']\n",
      "Vector for 'king': [ 0.50451   0.68607  -0.59517  -0.022801  0.60046  -0.13498  -0.08813\n",
      "  0.47377  -0.61798  -0.31012  -0.076666  1.493    -0.034189 -0.98173\n",
      "  0.68229   0.81722  -0.51874  -0.31503  -0.55809   0.66421   0.1961\n",
      " -0.13495  -0.11476  -0.30344   0.41177  -2.223    -1.0756   -1.0783\n",
      " -0.34354   0.33505   1.9927   -0.04234  -0.64319   0.71125   0.49159\n",
      "  0.16754   0.34344  -0.25663  -0.8523    0.1661    0.40102   1.1685\n",
      " -1.0137   -0.21585  -0.15155   0.78321  -0.91241  -1.6106   -0.64426\n",
      " -0.51042 ]\n",
      "Words similar to 'king': [('prince', 0.8236179351806641), ('queen', 0.7839043140411377), ('ii', 0.7746230363845825), ('emperor', 0.7736247777938843), ('son', 0.766719400882721), ('uncle', 0.7627150416374207), ('kingdom', 0.7542160749435425), ('throne', 0.7539913654327393), ('brother', 0.7492411136627197), ('ruler', 0.7434253692626953)]\n",
      "Embeddings for processed text: [array([-0.54313  ,  0.34427  ,  0.27125  ,  1.0487   , -1.1642   ,\n",
      "       -1.2722   ,  0.35781  , -0.56527  , -0.29879  ,  0.85179  ,\n",
      "        0.52222  , -0.0019718, -0.46435  ,  0.033631 ,  0.048367 ,\n",
      "        0.78762  ,  0.075995 ,  0.51577  ,  0.34778  ,  0.53802  ,\n",
      "        0.28299  , -0.1313   , -0.073753 ,  0.42614  ,  0.030954 ,\n",
      "       -0.55033  , -0.99789  , -0.28947  ,  0.30517  , -1.1194   ,\n",
      "        1.2957   ,  0.91165  ,  0.32222  ,  0.93405  , -0.34152  ,\n",
      "       -0.62713  , -0.092165 ,  0.50901  ,  0.29204  , -0.20122  ,\n",
      "        0.19614  , -0.45882  ,  1.1099   , -0.68737  ,  1.5724   ,\n",
      "       -0.10446  ,  0.23594  , -0.56594  ,  0.43676  ,  0.98093  ],\n",
      "      dtype=float32), array([ 0.2428   , -0.16033  , -0.59102  ,  1.6781   ,  0.12854  ,\n",
      "       -0.59667  ,  0.32641  ,  0.39337  , -0.0034547, -0.82054  ,\n",
      "       -0.20404  ,  0.81114  , -1.4266   , -1.0304   ,  0.2278   ,\n",
      "       -0.29447  ,  0.66657  , -0.35675  , -0.17686  ,  0.294    ,\n",
      "        0.026872 ,  0.60572  ,  0.041574 ,  0.41339  ,  0.99185  ,\n",
      "       -0.079221 , -0.041304 , -0.98891  , -0.40578  , -0.066497 ,\n",
      "       -1.0524   , -0.063194 ,  0.067709 ,  0.099585 ,  0.21086  ,\n",
      "        0.21201  , -0.70517  ,  0.69933  , -0.068512 ,  0.95889  ,\n",
      "        0.89135  ,  0.60123  ,  0.61118  , -0.72003  ,  0.70848  ,\n",
      "        0.57112  , -0.034414 , -0.18053  ,  0.71444  , -0.10678  ],\n",
      "      dtype=float32), array([ 0.2763   , -0.52348  , -0.39211  ,  0.20764  , -0.80132  ,\n",
      "       -0.48497  ,  0.40882  , -0.0040835, -0.052635 ,  0.17946  ,\n",
      "        0.032352 , -0.52223  , -0.0082647, -0.97411  , -1.0311   ,\n",
      "        0.28892  ,  0.079454 ,  2.1041   , -1.2363   ,  1.6507   ,\n",
      "        1.2276   ,  0.10214  ,  0.10908  ,  1.3289   ,  0.23197  ,\n",
      "       -0.68958  , -0.075935 , -0.22984  , -0.65604  , -0.89471  ,\n",
      "        0.21205  ,  0.66614  ,  0.39522  , -0.44094  ,  0.85986  ,\n",
      "        0.36946  ,  0.10928  ,  0.14226  ,  0.4193   ,  0.8327   ,\n",
      "       -0.53118  , -0.65324  , -0.38395  ,  0.12322  , -0.50029  ,\n",
      "        0.87313  ,  0.062493 ,  0.20089  ,  1.2858   , -0.82761  ],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Enter the text : \")\n",
    "\n",
    "processed_text = preprocess_text(text)\n",
    "print(\"Processed Text:\", processed_text)\n",
    "\n",
    "vector = word2vec_model['king']\n",
    "print(\"Vector for 'king':\", vector)\n",
    "\n",
    "similar_words = word2vec_model.most_similar('king')\n",
    "print(\"Words similar to 'king':\", similar_words)\n",
    "\n",
    "embeddings = preprocess_and_embed(text, word2vec_model)\n",
    "print(\"Embeddings for processed text:\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc05e2c-c8bd-4844-a745-77834e145577",
   "metadata": {},
   "source": [
    "## Working and Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e32ca2-6018-4eea-9b52-6a2d773e709a",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0552ac2-f573-4c94-ae1c-86d986db387a",
   "metadata": {},
   "source": [
    "This step involves several mini-steps to clean and prepare the text:\n",
    "\n",
    "Tokenization: Splitting the text into individual words or tokens.\n",
    "\n",
    "Example: \"The quick brown fox\" becomes [\"The\", \"quick\", \"brown\", \"fox\"].\n",
    "Stop-word Removal: Removing common words that don't add much meaning (like \"the\", \"and\").\n",
    "\n",
    "Example: [\"The\", \"quick\", \"brown\", \"fox\"] becomes [\"quick\", \"brown\", \"fox\"].\n",
    "Stemming: Cutting words down to their base form.\n",
    "\n",
    "Example: \"jumps\" becomes \"jump\".\n",
    "Lemmatization: Another way to reduce words to their base form, but more sophisticated than stemming.\n",
    "\n",
    "Example: \"running\" becomes \"run\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f4e55-1cae-44f8-8946-eb9726ad1989",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7278d200-4a41-4952-8e32-7a3700a84dc4",
   "metadata": {},
   "source": [
    "\n",
    "This step involves converting words into numbers (vectors) that a computer can understand and process. We use a model called Word2Vec for this.\n",
    "\n",
    "Load a Pre-trained Model: This model has already learned how to represent words as numbers.\n",
    "\n",
    "Example: The word \"king\" is represented by a vector (a long list of numbers).\n",
    "Find Similar Words: Using the Word2Vec model, we can find words that are similar in meaning.\n",
    "\n",
    "Example: \"king\" might be similar to \"queen\", \"prince\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8bcb3c-d8e5-4a3b-b30a-64f38351231c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
